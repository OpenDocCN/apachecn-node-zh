Service State and Interservice Communication <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 服务状态和服务间通信

现在我们已经开发了一些微服务，了解了 API Gateway，了解了服务注册和发现，现在是时候深入了解微服务，从单个微服务的角度来理解系统了。 为了从微服务体系结构中获得最大的好处，系统中的每个组件都必须以正确的方式进行协作——这种方式确保微服务之间很可能没有耦合，这将使我们成为敏捷的。

在本章中，我们将了解微服务之间的各种通信方式，并了解服务如何在它们之间交换数据。 然后我们将继续讨论服务总线，这是一种系统组件如何相互通信的企业方式。 许多服务需要以一种或另一种形式持久化某些状态。 我们将看到如何使我们的服务无状态。 我们将看到当前的数据库状况并了解服务状态。 我们将了解发布-子模式，并研究 Kafka 和 RabbitMQ 等工具，以了解事件驱动架构。 本章涵盖以下主题:

*   核心概念——状态、通信和依赖关系
*   沟通方式
*   数据共享的方式是同步还是异步
*   微服务版本控制和故障处理
*   服务总线
*   微服务之间的数据共享
*   缓存通过复述,
*   发布-订阅模式

# 核心概念——状态、通信和依赖关系

每个微服务实现一个单一的功能，比如运输，并从库存中扣除。 然而，要交付最终用户、服务请求(如业务能力、用户需求或特定于用户的请求); 它可能是一组业务功能，也可能不是。 例如，从用户的角度来看，想要购买产品的人是一个单一的服务请求。 但是，这里涉及多个请求，如添加到购物车微服务，支付微服务，发货微服务。 因此，要交付，微服务需要相互协作。 在本节中，我们将研究微服务协作的核心概念，如服务状态、通信风格等。 选择正确的通信风格有助于我们设计一个松散耦合的体系结构，以确保每个微服务具有明确的边界，并保持在其边界上下文中。 在本节中，我们将研究一些影响微服务设计和架构的核心概念。 让我们开始吧。

# Microservice 状态

虽然我们确实应该努力使服务尽可能地无状态，但在某些情况下，我们确实需要有状态的服务。 状态就是任何特定时间点的任何条件或质量。 有状态服务是依赖于系统状态的服务。 有状态意味着在时间上依赖这些时刻，而无状态意味着独立于任何类型的状态。

在我们有一个调用 REST 服务的工作流、我们需要在失败时支持重试、我们需要跟踪进度、存储中间结果等等的情况下，有状态服务是必不可少的。 我们需要将状态保持在服务实例边界之外。 这就是数据库发挥作用的地方。

数据库是值得思考的重要和有趣的部分。 在微服务中引入数据库的方式应该是，其他团队不能直接与我们的数据库对话。 事实上，他们甚至不应该知道我们数据库的类型。 当前的数据库环境有各种可供我们选择的选项，包括 SQL 和 NoSQL 类别。 甚至还有图形数据库、内存数据库和具有高读写能力的数据库。

我们的微服务可以有无状态和有状态的微服务。 如果服务依赖于状态，则应该将其分离到一个容易访问且不与任何人共享的专用容器中。 微服务在无状态时具有更好的扩展能力。 我们伸缩容器，而不是伸缩 VM。 因此，每个状态存储应该位于一个可以在任何时间点伸缩的容器中。 我们使用 Docker 来扩展数据库存储，这将创建一个独立于主机的独立持久化层。 新的云数据存储，如 Redis, Cassandra 和 DynamoDB，在一致性上以最小的延迟最大化可用性。 设计具有异步和可伸缩特性的有状态微服务需要对这个问题进行一些思考——在任何顺序消息之间找到某种通信状态的方法，并确保消息不会与它们不属于的任何上下文混淆。 在本章中，我们将看到实现这一目标的各种同步模式，如 CQRS 和 Saga。

维护状态并不是只能在服务级别上完成的事情。 实际上，在网络中有三个地方可以保持状态:

*   **HTTP**:这实际上是一个应用层，从这里状态主要是基于会话的或持久化在数据库中。 一般来说，通过维护客户机和应用程序或服务之间的通信层。
*   **TCP**:这实际上是传输层。 这里维护状态的目标是确保客户机和应用程序或服务之间有一个可靠的交付通道。
*   **SSL**:这是 TCP 和 HTTP 层之间没有 home 的层。 它提供了数据的机密性和隐私性。 这里维护状态，因为加密和解密仅依赖于客户端与应用程序或服务之间的连接所独有的信息。

因此，即使我们的服务是无状态的，TCP 和 SSL 层也需要维护状态。 所以你从来不是纯粹的无国籍者。 无论如何，在本书的范围内，我们将只关注应用程序层。

# 军种间的沟通

由于微服务是细粒度的，并且与某个范围密切相关，因此它们需要以某种方式进行协作，以便向最终用户交付功能。 它们要么需要共享状态或依赖关系，要么需要与其他服务通信。 让我们看一个实际的例子。 考虑一下频繁购买者奖励计划微服务。 这个微服务负责奖励经常买家的业务能力。 这个程序很简单，只要顾客买了东西，他们的账户就会累积一些积分。 现在，当顾客买东西时，他可以用这些积分在售价上打折。 微服务的回报取决于客户购买微服务等业务能力。 其他业务能力取决于奖励计划。 如下图所示，微服务需要与其他微服务协作:

![](assets/35077dd7-21de-47d6-a900-73df46b1d16f.png)

Need of microservices

如上图所示，微服务被细分为业务功能。 然而，最终用户的功能需要几个业务功能，微服务必须相互协作才能将用例交付给最终用户。 当任何微服务协作时，协作风格主要遵循三个类别:**命令**、**查询**和**事件**。 让我们通过一些例子来理解所有这三种类别。

# 命令

每当任何一个微服务需要另一个微服务执行一个操作时，就使用**命令**。 它们本质上是同步的，通常使用 HTTP POST 或 PUT 请求实现。 例如，在上图中，奖励程序微服务发送一个命令给用户配置微服务或发票微服务关于促销优惠的奖励。 当发送命令失败时，发送方将不知道接收方是否处理了该命令。 如果发送方和接收方都没有遵守一组规则，这可能会导致错误或某些功能降级。

# 查询

与命令类似，当一个微服务需要来自另一个微服务的一些信息时，使用查询。 例如，在我们的购物车微服务中开发票时，我们需要关于奖励积分总数的信息，以便给予促销折扣，因此开发票微服务查询奖励积分微服务。 这是一种同步通信模式，通常使用 HTTP GET 请求实现。 每当查询失败时，调用者就得不到它需要的数据。 如果调用者能够很好地处理异常，那么对某些降级功能的影响就很小。 如果它不能很好地处理错误，错误就会在整个系统中传播。

# 事件

虽然与标准方法不同，第三种方法是一种反应性的方法。 当一个微服务需要对另一个微服务中发生的事情作出反应时，通常首选事件。 定制日志微服务侦听所有其他服务的日志条目，以便将日志推送到 Elasticsearch。 类似地，奖励微服务侦听购物跟踪微服务，以便根据用户的购物情况相应地更新用户奖励。 当订阅者轮询任何事件提要时，如果调用失败，其影响非常有限。 订阅者稍后仍然可以轮询事件提要，直到事件提要启动并在任何时候开始接收事件。 有些事件会延迟，但这应该不是问题，因为所有事情都是异步完成的。

# 交换的数据格式

服务间通信的本质或基础是以任何格式交换消息。 消息通常包含数据，因此数据格式是一个非常重要的设计方面。 这将极大地影响通信的效率、可用性和变更，以及服务的及时发展。 选择跨消息格式是非常必要的。 有两种消息格式:**文本**和**二进制**。 在本节中，我们将研究这两种方法。

# 基于文本的消息格式

常用的消息格式(如 JSON 和 XML)是人类可读和自描述的。 这些格式使用户能够挑选出使用者感兴趣的值，并丢弃其余的值。 对模式格式的任何更改都可以轻松地实现向后兼容。 使用基于文本的格式的缺点包括本质上过于冗长和解析整个文本的开销。 为了提高效率，建议使用二进制格式。

# 二进制消息格式

这些格式提供了用于定义消息结构的类型化标识语言。 然后编译器生成代码，为我们序列化和反序列化消息(我们将在本章后面看到 Apache Thrift)。 如果客户端有静态类型语言，那么编译器将检查 API 是否被正确使用。 Avro、Thrift 和谷歌的 protobuf 是主要的二进制消息格式。

现在我们已经清楚地了解了通信的本质，我们可以继续下一节的依赖关系。 在继续进行之前，让我们总结一下要点。

如果满足以下用例，您可以选择使用命令和查询:

*   为了处理服务请求，服务客户机需要一个响应来进一步推进其流程。 例如，对于支付微服务，我们需要客户信息。
*   这种情况需要异步操作。 例如，只有在已经付款并为客户交货而处理产品时，才应该扣除库存。
*   对其他服务的请求是一个简单的查询或命令，也就是说，可以通过 HTTP`GET`、`PUT`、`POST`和`DELETE`方法处理。

如果满足以下用例，您可以选择使用事件:

*   当您需要扩展应用程序时，纯粹的命令和查询不能扩展到更大的问题集。
*   生产者或发送方不关心接收方或消费者端有多少额外的处理，它对生产者端没有这样的影响。
*   当多个客户端读取单个消息时。 例如，一个订单已经开了发票，然后需要执行多个流程，例如准备好分发、更新库存、发送客户端通知等等。

# 依赖关系

现在我们已经了解了微服务中的通信风格，接下来我们将学习开发中的下一件显而易见的事情——依赖和避免依赖地狱。 随着开发越来越多的微服务，您将发现跨多个微服务的代码重复。 要解决这些问题，我们需要理解依赖关系以及如何分离支持代码。 Node.js 有一个包管理器 NPM，它会获取应用程序的依赖(以及你依赖的依赖)。 NPM 支持私有存储库，可以直接从 GitHub 下载，建立自己的存储库(比如 JFrog、Artifactory)，这不仅有助于避免代码，还有助于部署过程。

然而，我们不能忘记**Microservices 101**。 我们做微服务是为了确保每个服务可以独立发布和部署，为此我们必须避免依赖地狱。 为了理解依赖地狱，让我们考虑以下示例，购物车微服务的 API 列出了产品，这些产品现在已经升级为 API 列出具有特定品牌的产品。 现在，所有对购物车微服务的依赖都可以发送一条消息来列出具有特定品牌的产品，这最初是为了列出产品。 如果不处理向后兼容性，那么这会演变成依赖地狱。 为了避免依赖地狱,策略,可以使用一些 api,必须向前和向后兼容,他们必须准确的文档,测试必须完成合同(我们将在[看到这第八章](08.html),*测试、调试、和记录*,在*协议*), 并使用适当的工具库，该工具库有明确的目标，在遇到未知字段时抛出错误。 为了确保我们想避免依赖地狱，我们必须简单地遵循以下规则:

*   一个微服务不能调用另一个微服务，也不能直接访问它的数据源
*   微服务只能通过基于事件的机制或一些微服务脚本(脚本可以是任何东西，如 API 网关、UI、服务注册表等)调用另一个微服务。

在下一节中，我们将研究微服务通信风格，并了解它们如何相互协作。 我们将研究基于不同分类因素的广泛使用的模式，并了解在什么时候使用哪种模式的场景。

# 沟通方式

微服务生态系统本质上是一个运行在多台机器上的分布式系统。 每个服务实例只是另一个进程。 我们在前面的图表中看到不同的流程通信。 在本节中，我们将更详细地学习沟通风格。

服务使用者和服务响应者可以通过许多不同类型的通信风格进行通信，每种通信风格都针对特定的场景和结果。 通信类型可以分为两个不同的方面。

第一个方面处理协议的类型，无论是同步的还是异步的:

*   通过命令和查询(如 HTTP)调用的通信本质上是同步的。 客户端发送一个请求来等待来自服务的响应。 这种等待是依赖于语言的，也就是说，它可以是同步的(语言，如 Java)，也可以是异步的(响应可以通过回调、承诺等来处理，在我们的例子中是 Node.js)。 重要的一点是，只有当客户端收到正确的 HTTP 服务器响应时，服务请求才能被服务。
*   其他协议，如 AMQP、套接字等，本质上是异步的(日志和购物跟踪器微服务)。 客户端代码或消息发送方不等待响应，它只是将消息发送到任何队列或消息代理。

第二个方面处理的是接收器的数量，是只有一个接收器还是有多个接收器:

*   对于单个接收器，每个请求只能由一个接收器或服务处理。 命令和查询模式就是这种通信的例子。 一对一交互包括请求/响应模型、单向请求(如通知)和请求/异步响应模型。
*   对于多个接收端，每个请求可以被零服务或多个接收端处理。 这是一种异步通信模式，使用了一个促进事件驱动体系结构的发布-订阅机制示例。 多个微服务之间的数据更新通过事件传播，这些事件通过一些服务总线(Azure 服务总线)或任何消息代理(AMQP、Kafka、RabbitMQ 等)实现。

# 次世代沟通方式

虽然我们看到了一些常见的沟通方式，但世界是在不断变化的。 随着世界各地的发展，甚至最基本的 HTTP 协议也在发展，我们现在有了 HTTP 2。 X 协议具有一些额外的优点。 在这一节中，我们将看看下一代通信风格，并看到它们所提供的优势。

# HTTP / 2

HTTP/2 提供了显著的增强，并且更多地关注于改进 TCP 连接的使用。 与 HTTP/1.1 相比，以下是一些主要的增强:

*   **压缩和二进制帧**:HTTP/2 内置了报头压缩，以减少以千字节(例如，cookie)增长的 HTTP 报头的占用。 它还控制在多个请求和响应中重复的头。 此外，客户端和服务器维护一个经常可见的字段列表以及它们的压缩值，因此当这些字段被重复时，个体只需要包含对压缩值的引用。 除此之外，HTTP/2 对帧使用二进制编码。
*   **多路复用**:与单一的请求和响应流(客户端在发出下一个请求之前必须等待一个响应)相比，HTTP/2 通过实现流引入了请求的完全异步多路复用(请注意响应式编程!) 客户机和服务器都可以在一个 TCP 连接上启动多个请求。 例如，当客户端请求一个网页时，服务器可以启动一个单独的流来传输该网页所需的图像和视频。
*   **流控制**:随着多路复用技术的引入，需要一个适当的流控制来避免任何流上的破坏性行为。 HTTP/2 为客户端和服务器提供构建块，使其具有适合任何特定情况的适当流控制。 流量控制允许浏览器只获取特定资源的一部分，通过将窗口减少到零来暂停该操作，并在任何时间点恢复。 此外，还可以设置优先级。

在这一节中，我们将看看如何在微服务系统中实现 HTTP/2。 您可以查看`example http2`下`chapter 7`，源代码遵循实现:

1.  Node.js 10 支持 HTTP/2。 XX，但还有其他方法可以实现支持，而无需升级到两周前刚刚引入的最新版本(Node.js 10)。 XX 是在两周前写这篇文章的时候推出的)。 我们将使用节点模块`spdy`，它为我们的`Express`应用程序提供 HTTP/2 支持。 复制第 2 章、*中的`first-microservice`骨架，将`spdy`安装为节点模块，命令如下:*

 *```
npm install spdy --save
```

2.  要使 HTTP/2 生效，必须启用 SSL/TLS。 为了使我们的开发环境正常工作，我们将自行生成 CSR 和证书，这些证书可以很容易地通过在生产环境中获取证书来替换。 要生成证书，请遵循以下命令:

```
// this command generates server pass key.
openssl genrsa -des3 -passout pass:x -out server.pass.key 2048
//we write our RSA key and let it generate a password
openssl rsa -passin pass:x -in server.pass.key -out server.key
rm server.pass.key //this command removes the pass key, as we are just on dev env
//following commands generates the csr file
openssl req -new -key server.key -out server.csr
//following command generates server.crt file
openssl x509 -req -sha256 -days 365 -in server.csr -signkey server.key -out server.crt
```

所有这些步骤的结果将产生三个文件:`server.crt`、`server.csr`和`server.key`。

3.  接下来，我们需要改变快速服务器的启动方式。 我们需要使用`spdy`提供的方法，而不是使用默认方法。 在`Application.ts`中做以下修改。 将`this.express.app.listen`替换为以下代码:

```
import * as spdy from 'spdy';
 const certsPath = path.resolve('certs');
 const options={         
     key:fs.readFileSync(certsPath+"/server.key"),
     cert:fs.readFileSync(certsPath+"/server.crt")
 }...
this.server=spdy.createServer(options,this.express.app)
                  .listen(port,(error:any)=>{                       
                  if(error){
                      logger.error("failed to start 
                      server with ssl",error);
                      return process.exit(1);}else{
                      logger.info(`Server Started! Express:                 
                      http://localhost:${port}`); }})
```

4.  我们准备开始分发 HTTP/2 请求。 启动服务器并打开`https://localhost:3000/hello-world`。 打开开发者控制台，你应该能够看到 HTTP/2，就像下面的截图:

![](assets/cf4057f7-f62e-4842-ab95-c2ed89c68b71.png)

HTTP support

这些是 HTTP 调用。 在下一节中，我们将研究 RPC 机制，这是在微服务之间进行协作的另一种方式。

# 使用 Apache Thrift 的 gRPC

gRPC 是一个为编写跨语言 RPC(远程过程调用)客户端和服务器而设计的框架。 它使用二进制格式，并专注于 API 优先的方法来设计任何服务。 它提供了固定的 IDL(交互式数据语言固定格式)，以便稍后生成遵循该固定 IDL 格式的客户端存根和服务器端框架。 编译器可以为大多数语言生成代码，它们使用 HTTP/2 交换数据，从长远来看这是有益的。 Apache Thrift 是编写跨语言 RPC 客户机和服务器的一个很好的替代方案。 它有一个 c 风格的 IDL 定义语言。 编译器为各种语言生成代码，包括 c++、Java，甚至 TypeScript。 Thrift 定义与 TypeScript 接口非常相似。 节约方法可以提供任何价值，也可以只是单向通信。 具有返回类型的方法实现请求/响应模型，而没有返回类型的方法定义为实现通知模型。 Thrift 支持 JSON 和二进制文件。 让我们从一个例子开始。 您可以按照[第 7 章](07.html)、*服务状态和服务间通信*中的`thrift-rpc`文件夹，在提取的源代码中。

我们要做的整个过程如下:

*   写一个`.thrift`文件，描述我们的产品微服务和流行微服务
*   为 TypeScript 生成源代码，我们要用这种语言来编写服务通信
*   导入生成的代码并开始编写我们的服务
*   在产品中包括产生的受欢迎的来源，并编写我们的服务
*   创建 API 网关作为单个入口点

Though Thrift provides Node.js and TypeScript libraries, we are going to use `npm` modules of **CreditKarma** ([https://github.com/creditkarma](https://github.com/creditkarma)), as original modules lack in generating strict types. So let's get started.

现在，让我们执行以下步骤:

1.  初始化 Node.js 项目。 不下载 Thrift，我将使用`npm`模块。 因此，将以下模块作为依赖项安装:

```
npm install  @creditkarma/dynamic-config  @creditkarma/thrift-client @creditkarma/thrift-server-core @creditkarma/thrift-server-express @creditkarma/thrift-typescript --save
```

2.  创建一个名为`thrift`的文件夹，并在其中创建两个 Thrift 文件——`PopularityService.thrift`(`thrift/popularity/PopularityService.thrift`)和`ProductService.thrift`(`thrift/product/ProductService.thrift`)。 Thrift 文件类似于 TypeScript 接口:

```
namespace js com.popularity
struct Popularity {
    1: required i32 id
    2: required i32 totalStars
    3: required string review
    4: required i32 productId}
exception PopularityServiceException {
    1: required string message}
service PopularityService {
    Popularity getPopularityByProduct(4: i32 productId) 
    throws (1: PopularityServiceException exp)}
```

由于我们需要产品内部的流行度，我们将在`ProductService.thrift`中导入它，您可以在这里检查其他默认语法[https://thrift.apache.org/docs/idl](https://thrift.apache.org/docs/idl)。

3.  现在，我们将使用前面步骤中定义的 IDL 文件生成代码。 打开`package.json`，在`scripts`标签中添加以下脚本:

```
"precodegen": "rimraf src/codegen",
"codegen": "npm run precodegen && thrift-typescript --target thrift-server --sourceDir thrift --outDir src/codegen"
```

这个脚本将为我们生成代码，因为我们只需输入`npm run codegen`。

4.  下一部分是编写`findByProductId`和`findPopularityOfProduct`方法。 在提取的源代码中查看`src/popularity/data.ts`和`src/product/data.ts`虚拟数据和虚拟查找方法。

5.  现在我们将编写启动`PopluarityThriftService`和`ProductThriftService`的代码。 在`src/popularity/server.ts`中创建一个`serviceHandler`，如下:

```
const serviceHandler: PopularityService.IHandler<express.Request> = {
    getPopularityByProduct(id: number, context?:  
    express.Request): Popularity {
        //find method which uses generated models and types.
},
```

6.  通过添加`ThriftServerExpress`作为中间件来启动这个`server.ts`为`express`:

```
app.use(serverConfig.path,bodyParser.raw(),
ThriftServerExpress({
    serviceName: 'popularity-service',
    handler: new PopularityService.Processor(serviceHandler),
}), ) 
app.listen(serverConfig.port, () => {//server startup code)})
```

7.  现在，在`src/product/server.ts`内部，添加以下代码，将对`PopularityService`进行 RPC 调用，以获得`productId`的普及:

```
const popularityClientV1: PopularityService.Client = createHttpClient(PopularityService.Client, clientConfig)
const serviceHandler: ProductService.IHandler<express.Request> = {
    getProduct(id: number, context?: express.Request):      
    Promise<Product> {
        console.log(`ContentService: getProduct[${id}]`)
        const product: IMockProduct | undefined = findProduct(id)
        if (product !== undefined) {
            return       
            popularityClientV1.getPopularityByProduct(product.id)
            .then((popularity: Popularity) => {
            return new Product({
            id: product.id,
            feedback:popularity,
            productInfo: product.productInfo,
            productType: product.productType,
        })
})} else {
throw new ProductServiceException({
    message: `Unable to find product for id[${id}]`,
})}},}
```

8.  同理，`create gateway/server.ts`。 为`/product/: productId`定义一个路由，它将对`ProductMicroservice`进行 RPC 调用，以获取所传递的`productId`的数据。
9.  运行程序并向`localhost:9000/product/1`发出请求，您将能够看到通过 RPC 调用的组合通信响应。

在本节中，我们对一些微服务通信风格以及一些实际操作有了亲身体验。 在下一节中，我们将了解如何对微服务进行版本控制，并使我们的微服务具有故障保护机制。

# 微服务版本控制和故障处理

进化是必要的，我们无法阻止它。 每当我们允许某个服务发展时，维护的最重要的方面之一就是服务版本控制。 在这一节中，我们将看到与处理系统中的更改以及克服系统中引入的任何故障相关的各个方面。

# 101 年版本

应该首先考虑服务版本控制，而不是在开发之后进行。 API 是服务器和消费者之间发布的契约。 维护版本可以帮助我们在不破坏现有客户的情况下发布新服务(不是每个人都接受第一次尝试的更改)。 旧版本和新版本应该共存。

流行的版本控制方式是使用语义版本。 任何语义版本将有三个主要组件——**主要**(每当有突破性的改变),**小**(只要有一个向后兼容的行为),和**补丁(向后兼容的任何 bug 修复)。 当微服务中有多个服务时，版本控制就会出现严重问题。 推荐的方法是在服务级别对任何服务进行版本控制，而不是在操作级别进行版本控制。 如果在任何操作中有单个更改，则将服务升级并部署到**Version2**(**V2**)，这适用于服务中的所有操作。 我们可以通过三种方式对任何服务进行版本化:**

*   **URI 版本控制**:服务的版本号包含在 URL 中。 我们只需要考虑这种方法的主要版本，因为这会改变 URL 路由。 如果有一个小版本或任何可用的补丁，使用者不需要担心更改。 为非版本 URI 保留最新版本的别名是需要遵循的良好实践之一。 例如，URL`/api/v5/product/1234`应该被别名为`/api/product/1234`—别名为`v5`。 另外，通过版本号也可以通过如下方式:

```
 /api/product/1234?v=1.5
```

*   **媒体类型版本控制**:媒体类型版本控制遵循一种略有不同的方法。 在这里，版本是由客户机在 HTTP Accept 报头上设置的。 其结构类似于`Accept: application/vnd.api+json`。 Accept 报头为我们提供了一种指定泛型和非泛型内容类型以及提供回退的方法。 像`Accept: application/vnd.api.v5+json`这样的命令专门要求 API 的`v5`。 如果省略了 Accept 头，使用者将与最新的版本交互，而最新的版本可能不是生产级的。 GitHub 使用这种类型的版本控制。
*   **自定义头**:最后一种方法是维护我们自己的自定义头。 消费者仍然会使用 Accept 头，并在其上添加一个新的头。 它应该是这样的:`X-my-api-version:1`。

在比较前面三种方法时，客户机在 URI 方法中使用服务很简单，但在 URI 方法中管理嵌套的 URI 资源可能很复杂。 与媒体类型版本控制相比，使用基于 uri 的方法迁移客户机是复杂的，因为我们需要维护多个版本的缓存。 然而，大多数大型参与者，如谷歌、Salesforce 等，都使用 URI 方法。

# 当开发者的噩梦成真

所有系统都会出现故障。 微服务的分布，可能性会非常高。 如何处理失败和对失败做出反应是定义开发者的关键。 虽然使整个产品生态系统具有弹性是非常了不起的(活动包括集群服务器、设置应用程序负载平衡器、在多个位置之间分布基础设施以及设置灾难恢复)，但我们的工作并不仅限于此。 本部分仅解决系统的完全丢失问题。 然而，当一个服务运行缓慢或存在内存泄漏时，很难检测到问题，原因如下:

*   服务降级开始缓慢，但迅速获得势头，并像感染一样传播。 应用程序容器将完全耗尽其线程池资源，系统将宕机。
*   太多同步调用，调用者必须无休止地等待服务返回响应。
*   应用程序不处理部分降级。 只要任何服务完全关闭，应用程序就会继续调用资源耗尽时很快就会存在的服务。

这种情况最糟糕的一点是，这种失败会像传染病一样蔓延开来，对整个系统产生负面影响。 一个性能不佳的系统可能很快就会导致多个相关系统的失效。 有必要保护服务的资源不因其他一些性能较差的服务而耗尽。 在下一节中，我们将研究这些模式中的一些，以避免系统中的故障级联和引起连锁反应。

# 客户端弹性模式

客户端弹性模式允许客户端快速失败，而不会阻塞数据库连接或线程池。 这些模式在客户机层实现，客户机层调用任何远程资源。 有以下四种常见的客户端弹性模式:

*   舱壁并重试
*   客户端负载均衡或基于队列的负载均衡
*   断路器
*   回退和补偿事务

图中可以看到这四种模式如下:

![](assets/236387ce-c92c-4ff1-a1e8-04fadc93b610.png)

Client resiliency patterns

# 隔离，再试一次

舱壁模式类似于建造一艘船的模式，在那里一艘船被划分成完全隔离和水密的隔间称为舱壁。 即使船体被戳破，也不会受到影响，因为船体被分成了不透水的隔间。 舱壁将水限制在船舶发生穿刺的特定区域内，防止船舶下沉。

类似的概念也应用在隔离模式中，用于与许多远程资源交互的服务。 通过使用这种模式，我们将对远程资源的调用分解到它们自己的隔离池(它们自己的线程池)中，从而降低风险并防止应用程序因为远程资源缓慢而宕机。 如果一个服务速度很慢，那么该类型服务的线程池将变得饱和，从而停止处理进一步的请求。 对另一个服务的调用不会受到阻碍，因为每个服务都有自己的线程池。 当应用程序试图连接到服务或任何网络资源时，重试模式通过透明地重试以前由于某些标准而失败的操作，帮助应用程序处理任何预期的临时失败。 它不是等待，而是进行固定次数的重试。

# 客户端负载平衡或基于队列的负载均衡模式

我们在[第 6 章](06.html)、*服务注册和发现*中看到了客户端负载平衡。 它涉及让客户机从任何服务发现代理(Eureka/Consul)查找服务的所有单个实例，然后缓存可用服务实例的位置。 当任何进一步的请求到来时，客户端负载平衡器将从客户端维护的服务位置池中返回一个位置。 位置按一定的间隔定期刷新。 如果客户端负载平衡器在任何服务位置检测到问题，它将从池中删除该问题，并阻止任何进一步的请求击中该服务。 例如，Netflix Ribbon。 另一种弹性方法包括添加一个队列，作为它调用的任何任务和/或服务之间的缓冲区，以便平稳地处理任何间歇负载，防止数据丢失。

# 断路器的模式

我们已经在[第一章](01.html)、*揭穿微服务*中看到了这种模式。 让我们快速回忆一下。 每当我们安装了一个断路器，并且调用远程服务时，断路器就会监控通话。 如果通话时间过长，断路器将终止通话并使电路打开，使它不可能允许任何进一步的通话。 这就是快速失败，快速恢复的概念。

# 回退和补偿事务模式

在此模式中，每当远程服务调用失败时，使用者将尝试执行另一种方法来执行该操作，而不是生成异常。 实现这一目标的方法通常包括从备用数据源(比如缓存)查找数据，或者将用户的输入排队以备将来处理。 用户将得到通知，他们的请求将在稍后处理，如果所有路由失败，系统将尝试补偿已处理的任何操作。 我们使用的一些常见的退避方法是(由 Netflix 突出显示):

*   **Cache**:从本地或远端缓存中获取数据，如果缺少实时依赖，可以定期刷新缓存数据，避免数据过期
*   **最终一致性**:当服务可用时，将数据保存在队列中以待进一步处理
*   **存根数据**:保持默认值，并在个性化或服务响应不可用时使用这些值
*   **空响应**:返回空列表

现在，让我们看一些实际案例研究，以处理失败并防止它们的连锁反应或引起连锁反应。

# 案例研究——NetFlix 堆栈

在这个案例研究中，我们将拥抱 Netflix 堆栈，并在我们的微服务中采用它。 从一开始我们就听说:多语言开发环境。 我们在这里做同样的事情。 在本节中，我们将使用 ZUUL 设置 API Gateway，使用 Java 和 Typescript 添加自动发现功能。 用户将不知道实际命中的是哪个请求，因为他只访问 Gateway。 案例研究的第一部分介绍了 Zuul, Eureka 和注册其中的一些服务，以及如何通过中央网关进行通信。 下一部分将处理更重要的事情，如如何处理负载平衡、安全性等。 让我们开始吧。 您可以跟随`Chapter 7/netflix`云文件夹中的示例。 除非有必要，否则我们不会重新发明轮子。 让我们最大限度地利用这些东西。 下面的案例研究支持并鼓励多语言架构。 让我们开始吧。

# 祖尔语和多语言环境

让我们来看看以下步骤:

1.  首先我们需要的是一个网关([第五章](05.html),*理解 API 网关*)和服务注册和发现(第六章,*服务注册和发现*)解决方案。 我们将利用 Netflix OSS 的 Zuul 和 Eureka。
2.  首先我们需要一个尤里卡服务器,从`Chapter-6/ eureka/eureka-server`复制源到一个新的文件夹或遵循的步骤从第六章,*服务注册和发现,尤里卡部分中创建一个新的服务器将在 JVM 上运行。*
**   不做任何花哨的事情，只是在相关的地方添加注释`@EnableEurekaServer`和`@SpringBootApplication`-`DemoServiceDiscoveryApplication.java.`*

 *4.  通过添加以下内容在`application.properties`文件中配置端口号、健康检查等属性:

```
eureka:
  instance:
    leaseRenewalIntervalInSeconds: 1         
    leaseExpirationDurationInSeconds: 2
  client:
  serviceUrl:
    defaultZone: http://127.0.0.1:8761/eureka/
    registerWithEureka: false
    fetchRegistry: true
  healthcheck:
    enabled: true
  server:
    port: 8761
```

5.  运行 Eureka 服务器命令如下:

```
mvn clean install && java -jar target\demo-service-discovery-0.0.1-SNAPSHOT.jar
```

您应该能够看到 Eureka 服务器在端口`8761`中启动并运行。

6.  下一个是 Zuul 或者说我们的 API 网关。 Zuul 将作为任何服务请求的路由点，并且它将与 Eureka 服务器保持不断的联系。 我们将启用 Zuul 的自动注册服务，也就是说，如果任何服务注册或注销，我们将不必重新启动 Zuul。 将我们的网关放在 JVM 而不是 Node.js 中也会带来显著的持久提升。
7.  打开[https://start.spring.io/](https://start.spring.io/)，通过添加 Zuul 和 Eureka 发现作为依赖来生成项目。 (你可以在`Chapter 7/netflix cloud`下面找到`zuuul-server`)。
8.  打开`NetflixOsssApplication`并在其上添加以下注释。

```
@SpringBootApplication
@EnableDiscoveryClient
@EnableZuulProxy
public class NetflixOsssApplication { ...}
```

9.  接下来，我们将使用应用级属性配置我们的 Zuul 服务器:

```
server.port=8762
spring.application.name=zuul-server
eureka.instance.preferIpAddress=true
eureka.client.registerWithEureka=true
eureka.client.fetchRegistry=true
eureka.serviceurl.defaultzone=http://localhost:9091/eureka/
```

10.  通过`mvn clean install && java -jar target\netflix-osss-0.0.1-SNAPSHOT.jar`运行应用程序
11.  你应该能够看到你的 Zuul 服务器注册在 Eureka 仪表板，这意味着 Zuul 已经成功运行。
12.  接下来，我们在 Node.js 和 Java 中创建一个服务，并在 Eureka 中注册它，由于 Zuul 启用了自动注册，我们的服务将直接路由，不需要任何其他配置。 哇!
13.  首先，让我们创建一个 Node.js 微服务。 通过在`Application.ts`(Express 初始化的地方)中添加以下代码，在 Eureka 注册你的微服务:

```
 let client=new Eureka({
     instance: {
         instanceId:'hello-world-chapter-6',
         app: 'hello-world-chapter-6',
         //other attributes
     }, vipAddress: 'hello-world-chapter-6',
     eureka: {
         host: 'localhost',
         port: 8761,
         servicePath: '/eureka/apps/',
     }
 });
```

We did nothing new, this is same code we had in [Chapter 6](06.html), *Service Registry and Discovery*. Just remember that `instanceId`, `vipAddress` should be same.

14.  现在通过`npm start`运行该服务。 它将在端口`3001`中打开，但是我们的 Zuul 服务器正在端口`8762`中监听。 因此，点击 URL`http://localhost:8762/hello-world-chapter-6`，其中`hello-world-chapter-6`是`vipAddress`或应用程序名称。 您将能够看到相同的输出。 这证实了我们的 Zuul 服务器的工作。

15.  为了进一步理解微服务，我在 Java 中添加了一个微服务(`http://localhost:8080/product`)(没什么特别的，只是一个 GET 调用，检查文件夹`java-microservice`)。 在注册了运行在端口`8080`的微服务后，当我通过我的网关(`http://localhost:8762/java-microservice-producer/product`)检查它时，它就像一个咒语。

Another feasible option for us includes using Netflix Sidecar. 14\. Let's take a break and pat yourself. We have achieved auto registration/deregistration which can handle service in any language. We have created a polyglot environment.

# B 部分- Zuul，负载平衡和故障恢复

哇! ! *A 部分*很棒。 我们将走上同样的道路。 下一个问题是，当交通拥挤时会发生什么。 在这一部分，我们将看到如何利用 Zuul 在构建 Netflix Ribbon 支持负载平衡请求没有太多的喧嚣或大惊小怪。 每当请求到达 Zuul 时，它都会选择它找到的一个可用位置，并将服务请求转发给那里的实际服务实例。 缓存实例的位置、定期刷新它以及
将请求转发到实际位置的整个过程是开箱即用的，不需要任何配置。 在幕后，Zuul 使用 Eureka 来管理路由。 此外，我们将在本例中看到断路器，并在 Hystrix 仪表板中配置它，以查看实时分析。 在本节中，我们将配置断路器并将这些流发送到 Hystrix。 让我们开始吧。 您可以按照示例`Chapter 7/ hystrix`:

1.  在提取的源代码中抓取`standalone-hystrix-dashboard-all.jar`并点击`java -jar standalone-hystrix-dashboard-all.jar`命令。 这将在端口`7979`中打开 Hystrix 仪表板。 验证 URL`http://localhost:7979/hystrix-dashboard`检查:

![](assets/00fa516c-e477-4428-90f8-2055fba54958.png)

2.  是时候写一个简单的程序了，它会在某个时候打开一个电路。 我们将利用`opossum`模块([https://www.npmjs.com/package/opossum](https://www.npmjs.com/package/opossum))跳闸打开电路。 通过`npm install opossum --save`命令安装负鼠模块，并写下它的自定义类型，因为它们还不可用。

3.  我们会写一个简单的逻辑。 我们将初始化一个数字，如果它达到阈值，那么电路将处于断开-打开状态，我们的回退函数将达到。 让我们做必要的。
4.  让我们定义变量:

```
private baseline:number;
private delay:number;
private circuitBreakerOptions = {
    maxFailures: 5,
    timeout: 5000,
    resetTimeout: 10000, //there should be 5 failures
    name: 'customName',
    group: 'customGroupName'
};
```

5.  我们从第 20 条开始，使用两个变量在时间上进行比较:

```
this.baseline=20;
 this.delay = this.baseline;
```

6.  我们定义了`circuitBreaker`并指导我们的 express app 使用:

```
import * as circuitBreaker from 'opossum';
    const circuit = circuitBreaker(this.flakeFunction,   
    this.circuitBreakerOptions);
    circuit.fallback(this.fallback);
    this.app.use('/hystrix.stream', 
    hystrixStream(circuitBreaker));
    this.app.use('/', (request:any, response:any) => {
        circuit.fire().then((result:any) => {
            response.send(result);
        }).catch((err:any) => {
            response.send(err);
    });
});
```

7.  我们定义一个函数，它随时间增加，直到打开为止。 我们定义了一个回退函数，比如 Oops! 服务:

```
flakeFunction= ()=> {
    return new Promise((resolve, reject) => {
        if (this.delay > 1000) {
            return reject(new Error('Flakey Service is Flakey'));
        }
        setTimeout(() => {
            console.log('replying with flakey response 
            after delay of ', this.delay);
            resolve(`Sending flakey service. Current Delay at   
              ${this.delay}`);
            this.delay *= 2;
        }, this.delay);
    });
 }
 callingSetTimeOut(){
     setInterval(() => {
         if (this.delay !== this.baseline) {
              this.delay = this.baseline;
              console.log('resetting flakey service delay',    
              this.delay);
         }
     }, 20000);
 }
 fallback () => { return 'Service Fallback'; }
```

8.  就是这样! 打开 Hystrix，在 Hystrix 流中输入 URL`http://localhost:3000/hystrix.stream`，您将能够看到电路的实时监控:

![](assets/efa92def-d38f-4d51-8656-8cbf38b0fd0e.png)

一旦到达顶峰阶段，它就会被打开:

![](assets/4992df36-cc89-4678-bbeb-0f219ea4b1c8.png)

在预配置时间之后，它将再次处于关闭状态，并准备好服务请求。 详细的 API 可以在这里找到[https://www.npmjs.com/package/opossum](https://www.npmjs.com/package/opossum)。

# 消息队列和代理

消息队列是应用程序与应用程序通信问题的解决方案。 无论我的应用程序或数据在哪里，无论我在相同的服务器上、独立的服务器上、具有不同操作系统的服务器上或任何类似的服务器上，都会发生这种通信。 消息队列是为任务列表或工作队列等场景构建的。 消息队列通过通过队列传递和发送数据来解决这个问题。 然后应用程序利用消息中的信息进行进一步交互。 提供的平台安全可靠。 而构建 Message 代理是为了扩展消息队列的功能，它能够理解在代理中移动的每个消息的内容。 处理在每个消息上定义的一组操作。 与消息代理一起打包的消息处理节点能够理解来自不同来源(如 JMS、HTTP 和文件)的消息。 在本节中，我们将详细研究消息总线和消息代理。 流行的消息代理包括 Kakfa、RabbitMQ、Redis 和 NSQ。 在下一节中，我们将详细了解 Apache Kakfa，它是消息队列的高级版本。

# 发布/子模式介绍

就像消息队列一样，发布-订阅(发布-订阅)模式将信息从生产者移动到消费者。 但是，这里的主要区别在于此模式允许多个使用者接收主题中的每条消息。 它确保使用者按照在消息传递系统中接收消息的完全相同的顺序接收主题中的消息。 通过一个真实的场景可以更好地理解这个模式。 以股票市场为例。 它被大量的人和应用程序使用，所有人都应该实时发送消息，并且只是价格的确切顺序。 股票上涨到下跌和下跌到上涨是有很大区别的。 让我们看一个例子，Apache Kafka 是一个闪亮的解决方案，当它涉及发布子模式。 kafka 是一个分布式的，分区的，复制的提交日志服务。 它提供了消息传递系统的功能，但具有独特的设计。

Kafka 是一个流媒体平台，允许应用程序获取和获取消息。 它用于制作实时数据流水线流应用程序。 让我们来熟悉一下卡夫卡的术语:

*   生产者是向 Kafka 发送数据的人。
*   消费者是从 Kafka 读取数据的人。
*   数据以记录的形式发送。 每个记录都与一个主题相关联。 一个主题有一个类别，它由一个键、一个值和一个时间戳组成。
*   消费者通常订阅给定的主题，并获得一系列记录，每当有新记录出现时，他们都会收到提醒。
*   如果一个消费者下降了，他们可以通过跟踪最后的偏移量来重新启动流。
    保证消息的顺序。

我们将分三个阶段展开个案研究:

1.  在本地安装 Kakfa:
    1.  要在本地设置 Kakfa，请下载包并将其解压缩到选定的位置。 一旦提取，我们需要设置 Zookeeper。 通过以下命令——`bin\windows\zookeeper-server-start.bat config\zookeeper.properties`启动`zookeeper`。 Java 8 对于这个案例研究是必不可少的。 因为我在这个例子中使用的是 windows，所以我的命令中有`Windows`文件夹。 一定要注意`.sh`和`.bat`的区别。
        接下来我们将启动 Kakfa 服务器。 点击以下命令-
        `bin\windows\kafka-server-start.bat config\server.properties`。 【释义】 我们将创建一个名为 offers 的主题，该主题只有一个分区和一个副本`bin\windows\kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic offers`。 您将得到一个提示创建主题提供。 我们可以点击`bin\windows\kafka-topics.bat --list --zookeeper localhost:2181`查看主题。
        Kakfa 在`localhost:2181`上启动并运行。 我们甚至可以通过代理或 Node.js 客户端创建主题。

2.  创建一个卡夫卡制作人
    1.  我们将利用`kakfa-node`模块([https://www.npmjs.com/package/kafka-node](https://www.npmjs.com/package/kafka-node))。 根据需要，我们可以设置一个单独的服务，也可以集成到现有的应用程序服务中。
    2.  现在，我们将在两个不同的项目中编写两个独立的文件来测试我们的应用程序。
    3.  你可以检查`Chapter-8/kakfka/node-producer`来检查来源:

```
const client = new kafka.Client("http://localhost:2181", "kakfka-client", {
     sessionTimeout: 300,
     spinDelay: 100,
     retries: 2
 });
 const producer = new kafka.HighLevelProducer(client);
 producer.on("ready", function() {
     console.log("Kafka Producer is ready.");
 });
 // For this demo we just log producer errors
 producer.on("error", function(error:any) {
     console.error(error);
 });
 const KafkaService = {
     sendRecord: ({ type, userId, sessionId, data }:any,  
       callback = () => {}) => {
         if (!userId) {
             return callback(new Error(`A userId
                has to be provided.`));
         }
         const event = {
             id: uuid.v4(),
             timestamp: Date.now(),
             userId: userId,
             sessionId: sessionId,
             type: type,
             data: data
         };
         const buffer:any = new    
           Buffer.from(JSON.stringify(event));
         // Create a new payload
         const record = [
         {
             topic: "offers",
             messages: buffer,
             attributes: 1
         }
         ];
         //Send record to Kafka and log result/error
         producer.send(record, callback);
     }
 };
```

3.  您可以像这样绑定 on 消息事件。 通过相同的模块，我们可以创建一个客户端，它将侦听报价消息并相应处理事件:

```
const consumer = new kafka.HighLevelConsumer(client, topics, options);
 consumer.on("message", function(message:any) {
     // Read string into a buffer.
     var buf = new Buffer(message.value, "binary");
     var decodedMessage = JSON.parse(buf.toString());
     //Events is a Sequelize Model Object.
     return Events.create({
         id: decodedMessage.id,
         type: decodedMessage.type,
         userId: decodedMessage.userId,
         sessionId: decodedMessage.sessionId,
         data: JSON.stringify(decodedMessage.data),
         createdAt: new Date()
     });
 });
```

Kafka 是一个强大的玩家，它可以用于各种我们实际需要实时数据处理的事情。 发布/订阅模式是实现事件驱动通信的一种很好的方式。

# 共享依赖关系

通过独立部署、分离关注点、更好的弹性、多语言技术以及更好的模块化、可重用性和开发生命周期，微服务在构建可伸缩代码库方面非常出色。 然而，模块化和可重用性是有代价的。 更多的模块化和可重用性通常会导致高耦合或代码重复。 将许多不同的服务连接到同一个共享库将很快把我们带回到起点，我们将以巨大的地狱告终。

在这一节中，我们将看到如何克服这个地狱。 我们将看到一些具有实际实现的选项，并了解共享代码和公共代码过程。 让我们开始吧。

# 问题与解决方案

在微服务之间共享代码总是很棘手。 我们需要确保共同的依赖不会破坏我们的微服务自由。 在共享代码时，我们希望实现的主要目标是:

*   在我们的微服务中共享公共代码，同时确保我们的代码是**Don't Repeat Yourself**(**DRY**)——这是一个编码原则，主要目的是减少代码的重复
*   避免通过任何公共共享库进行紧密耦合，因为它消除了微服务的自由度
*   启用简单的更改，以便同步我们可以在我们的微服务之间共享的代码

微服务是一种引入代码复制的东西。 为任何此类业务用例创建带有新代码基的`npm`包是非常不切实际的，因为它将生成大量开销，使维护任何代码更改变得更加困难。

我们将使用**位**([https://bitsrc.io/](https://bitsrc.io/))来解决我们的依赖问题并实现我们的目标。 Bit 的运作理念是，组件是构建模块，而你是架构师。 使用 bit，我们不需要创建一个新的存储库或添加包来共享代码，而不是复制它。 您只需要定义任何现有微服务的可重用部分，并将其作为任何包或跟踪源代码共享给其他微服务。 通过这种方式，我们可以轻松地使任何服务的某些部分可重用，而无需修改任何一行代码，也不会在服务之间引入紧密耦合。 bit 的主要优势在于，它为我们提供了对代码进行更改的灵活性，这些更改将与任何其他服务共享，因此允许我们在微服务生态系统的任何地方开发和修改代码。

# 从比特开始

通过公共库耦合微服务是非常糟糕的。 Bit 促进构建组件。 我们只是隔离和同步任何可重用代码，并让 bit 处理如何隔离和跟踪项目中的源代码。 它仍然可以安装在 NPM 中，并在任何一端进行更改。 让我们假设您正在制作一个具有世界各地都很常见的顶级功能的伟大系统。 您希望在这些服务之间共享代码。 您可以按照[第 7 章](07.html)、*服务状态和服务间通信*中的代码进行操作:

1.  Bit 将被安装为一个全局模块。 安装`bit`，输入以下内容:

```
npm install bit-bin -g
```

2.  对于这个示例，请查看`demo-microservice`，它具有公共实用工具，比如从缓存中获取、公共日志记录实用工具等等。 我们希望这些功能无处不在。 在这里，我们将使用`bit`使我们的文件`common/logging.ts`随处可见。
3.  初始化`bit`并告诉`bit`将`logging.ts`添加到跟踪列表中的时间。 在终端中打开`demo-microservice`，输入`bit init` 命令。 这将创建一个`bit.json`文件。
4.  接下来，我们将告诉`bit`开始跟踪`common`文件夹。 在终端中点击以下命令:

```
bit add src/common/*
```

这里我们使用`*`作为全局模式，这样我们就可以跟踪同一路径上的多个组件。 它将跟踪`common`文件夹内的所有组件，您应该能够看到跟踪两个新组件的消息。

5.  钻头组件被添加到我们的钻头跟踪列表中。 我们只需点击`bit status`就可以查看微服务中的位的当前状态。 它将在 New components 部分下显示两个组件。
6.  接下来，我们将添加构建和测试环境，以便在共享组件之前不会在生态系统中引入任何异常。 首先是我们的构建环境。 构建环境本质上是一个构建任务，bit 使用它来运行和编译组件，因为我们的文件是用 TypeScript 编写的。 要导入依赖项，您需要在[https://bitsrc.io](https://bitsrc.io)创建一个帐户，并注册到公共层。

7.  通过添加以下代码来导入 TypeScript 编译器:

```
bit import bit.envs/compilers/typescript -c
```

您需要为刚才创建的帐户输入用户凭据。 一旦安装完毕，我们将在目前的公共范围内进行。

8.  点击命令`bit build`查看带有生成文件的`distribution`文件夹。 您可以编写类似的测试来检查单元测试用例是否通过。 Bit 内置支持 mocha 和 jest。 我们现在就创建一个`hello-world`测试。 我们需要为哪个组件指定位，这将是显式的`test`文件。 所以让我们取消之前添加的文件，因为我们需要传递我们的规格文件:

```
bit untrack --all
```

9.  在`src`中创建一个`test`文件夹，并按以下命令安装测试库:

```
npm install mocha chai @types/mocha @types/chai --save
```

10.  在`tests`文件夹中创建`logging.spec.ts`并添加以下代码。 类似地，创建`cacheReader.spec.ts`:

```
import {expect} from 'chai';
describe("hello world mocha test service", function(){
    it("should create the user with the correct name",()=>{
        let helloDef=()=>'hello world';
        let helloRes=helloDef();
        expect(helloRes).to.equal('hello world');
    });});
```

We will see detailed testing concepts in [Chapter 8](08.html), *Testing, Debugging, and Documenting*.

11.  要告诉`bit`我们的测试策略，点击以下命令:

```
bit import bit.envs/testers/mocha --tester
bit add src/common/cacheReader.ts  --tests 'src/tests/cacheReader.spec.ts'
bit add src/common/logging.ts --tests 'src/tests/logging.spec.ts'
```

12.  点击命令`bit test`，它将根据添加的每个组件打印测试结果。
13.  我们都做完了。 是时候与世界分享我们的全新组件了。 首先，我们将锁定一个版本，并将其与项目中的其他组件隔离。 点击以下命令:

```
bit tag --all 1.0.0
```

您应该能够看到一个输出，说明添加的组件`common/logging@1.0.0`和`common@cache-reader@1.0.0`。 当您执行`bit status`操作时，您将能够看到这些组件已从新组件转移到分段组件。

14.  为了与其他服务共享它，我们使用`bit export`导出它。 我们将把它推到远程范围，以便可以从任何地方访问它。 转到[http://bitsrc.io/](http://bitsrc.io/)，登录，然后在那里创建一个新范围。 现在我们将把我们的代码推到这个范围:

```
bit export <username>.<scopename>
```

您可以登录到您的帐户，然后在推入的存储库中检查代码。

15.  要在其他工作区中导入，你可以遵循以下步骤:
    1.  我们需要告诉节点，该位是从何处下载模块的注册表之一。 因此，在`npm config`中添加`bit`存储库作为别名`@bit`的注册表之一:

```
npm config set '@bit:registry' https://node.bitsrc.io
```

2.  要从任何其他项目下载，使用以下:

```
npm i @bit/parthghiya.tsms.common.logging
```

命令类似于`npm i <alias we created>/<username>.<scopename>.<username>`。 安装之后，就可以像使用其他任何节点模块一样使用它。 请查看`chapter 9/bit-code-sharing/consumer`。

您还可以使用`bit import`和其他实用程序，比如进行更改、同步代码等等。

对于开发和维护产品来说，共享代码是必须的。 然而，通过共享库的紧密耦合服务破坏了拥有微服务的意义。 在 NPM 中为任何新的通用用例创建新的存储库都是不切实际的，因为我们必须进行许多更改。 像 bit 这样的工具是两全其美的。 我们可以轻松地共享代码，也可以从任何一端进行更改和同步。

# 共享数据的问题

在微服务之间共享数据是一个巨大的陷阱。 首先，单个数据库可能无法满足微服务的所有需求。 此外，它还增加了开发时间耦合。 例如，`InventoryService`将需要与使用相同表的其他服务的开发人员协调模式更改。 它还增加了运行时耦合。 例如，如果一个长时间运行的`ProductCheckOut`服务持有`ORDER`表的锁，那么使用该表的任何其他服务将被阻塞。 每个服务必须有自己的数据库，并且数据不能被任何其他服务直接访问。

然而，有一个巨大的情况，我们需要照顾。 事务的问题以及如何处理它们。 尽管将事务相关的实体保存在同一个数据库中并利用数据库事务似乎是唯一的选择，但我们不能这样做。 让我们看看我们应该怎么做:

*   **选项 1**:如果任何更新只发生在一个微服务中，那么我们可以利用异步消息传递/服务总线来为我们处理。 服务总线将保持双向通信，以确保业务能力的实现。
*   **选项 2**:这是我们希望处理事务性数据的地方。 例如，结帐应该只发生在付款完成的情况下。 如果没有，那么就不应该继续进行任何事情。 要么我们需要合并服务，要么我们可以使用事务(比如用于分布式事务的谷歌 Spanner)。 我们有两个选择，要么通过交易解决问题，要么相应处理情况。 让我们看看如何以不同的方式处理这些场景。

为了管理数据一致性，最广泛使用的模式之一是 saga 模式。 让我们了解一个实际的用例。 我们有一个顾客奖励积分服务，保持总允许的点数购买。 应用程序必须确保新订单不得超过客户允许的奖励积分。 由于订单和客户积分在不同的数据库中，我们必须保持数据的一致性。

按照 saga 模式，我们必须实现跨越多个服务的每个业务事务。 它将是一个本地事务序列。 每个单独的事务更新数据库并发布消息或事件，这些消息或事件将触发传奇中的下一个本地事务。 如果本地事务失败，则 saga 执行一系列补偿事务，这些事务实际上撤消前一个事务所做的更改。 下面是我们将在本例中执行的步骤。 这是通过事件维护一致性的一种情况:

*   Rewards 服务创建一个待定状态的订单，并发布一个已处理积分的事件。
*   客户服务收到事件并试图阻止该订单的奖励。 它会发布奖励阻塞事件或奖励阻塞失败事件。
*   订单服务接收事件并相应地更改状态。

使用的最主要的模式如下:

*   **状态存储**:服务记录状态存储中所有的状态变化。 当出现任何故障时，我们可以查询状态存储以查找和恢复任何未完成的事务。
*   **流程管理器**:侦听由任何操作生成的事件并决定是否完成事务的流程管理器。

*   **路由 slip**:另一种主要的方法是使所有操作异步。 一个服务在一个名为 routing slip 的 slip 中使用两个请求命令(借方指令和运输指令)生成一条消息。 此消息将从路由单传递到借记服务。 借记服务执行第一个命令，并在将消息传递给完成运送操作的运送服务之前填充 routing slip。 如果出现故障，则将消息发送回错误队列，在该队列中，服务可以查看状态和错误状态，以便在需要时进行补偿。 下面的图表描述了相同的过程:

![](assets/77501b19-b2df-4878-9ce0-0e26bc299433.png)

Routing slip

如果处理不当，微服务中的数据共享始终是一件痛苦的事情。 对于跨微服务的分布式事务有各种解决方案。 我们看到了广泛使用的解决方案，如 saga，并通过各种方法处理数据最终的一致性。

# 缓存

现在我们已经掌握了微服务开发的主动权。 我们开发了微服务，通过网关连接它们，并在它们之间建立了一个通信层。 由于我们将代码分发到各种服务中，可能会出现的问题之一是在正确的时间访问急需的数据。 使用内存有它自己的一组挑战，我们永远不希望引入这些挑战(例如，您需要引入负载平衡器、会话复制器等等)。 我们需要某种方式来访问跨服务的临时数据。 这将是我们的缓存机制:一个服务在缓存中创建和存储数据，而其他服务可能根据需要和情况或故障使用它。 在这里，我们将引入 Redis 作为我们的缓存数据库。 突出的缓存解决方案包括 Redis 和 Hazelcast。

# 缓存的福与祸

每当我们被告知要优化应用程序的性能方面时，首先想到的就是缓存。 缓存可以被定义为在数据存储(服务器的 RAM，像 Redis 这样的键值存储)中暂时保存检索或计算的数据的过程，希望未来访问这些信息会更快。 这个信息的更新可能会被触发，或者这个值可能会在一段固定的时间间隔后失效。 缓存的优点乍一看似乎很大。 计算一次资源，然后从缓存(读取效率高的资源)中获取，避免了频繁的网络调用，因此它可以缩短加载时间，提高网站的响应速度，并为最终用户带来更多的收益。

然而，缓存并不是一站式解决方案。 对于静态内容和在某种程度上能够容忍陈旧数据的 api 来说，缓存确实是一种有效的策略，但在数据非常庞大和动态的情况下，它并不适用于其他地方。 例如，考虑购物车微服务中给定产品的库存。 对于受欢迎的产品，这个计数将很快改变，而对于其他一些产品，它可能会改变。 因此，确定贮藏物的正确年龄是一个相当大的难题。 添加缓存会引入需要管理的其他组件(如 Redis、Hazelcast、Memcached 等)。 它增加了成本、采购、配置、集成和维护的过程。 缓存也会带来其他危险。 有时从缓存读取可能很慢(缓存层没有得到适当维护，缓存处于网络边界之内，等等)。 通过更新部署来维护缓存也是一个巨大的噩梦。

为了有效地使用缓存，也就是减少我们的服务工作量，以下是一些需要保持的做法:

*   使用 HTTP 标准(例如 If-modified-Since 和 Last-Modified 响应报头等标准)。
*   其他选项包括 ETag 和 If-none-match。 在第一次调用后，生成一个唯一的**Entity 标签**(**ETag**)，并发送给业务请求，客户端在*if-none-match-header*中发送该标签。 当服务器发现 ETag 没有被更改时，它会发送一个带有`304 Not Modified`响应的空体。
*   HTTP Cache-Control 报头可用于帮助服务控制所有缓存实体。 它有各种属性,如私人**(不允许缓存内容包括如果这个头),**no - cache**(迫使服务器重新提交新的调用),**公共**(任何响应标记为可缓存),**和**信息被缓存(最长时间)。**

看看下面的图表，了解一些缓存场景:

![](assets/63da78bd-f083-4e76-bcbe-0c706ca5bc3f.png)

Cache scenarios

# 介绍复述,

Redis 是一个简单的 NoSQL 数据库，专注于简单的数据结构(键值对)，具有高可用性和读取效率。 Redis 是开源的，在内存数据结构存储，可以用作数据库，缓存或消息代理。 它可以选择内置的数据结构，比如字符串、散列、列表、集合、范围查询、地理空间索引等等。 它具有开箱即用的内置复制、事务、不同级别的磁盘持久性，以及高可用性和自动分区选项。 我们还可以添加持久存储，而不是使用内存存储。

Redis 与 Node.js 结合在一起就像天作之合，Node.js 在网络 I/O 方面非常高效。 NPM 存储库有很多 Redis 包来平滑我们的开发。 前身是`redis`([https://www.npmjs.com/package/redis),`ioredis`【显示】(](https://www.npmjs.com/package/redis)[https://www.npmjs.com/package/ioredis)和`hiredis`](https://www.npmjs.com/package/ioredis)([https://www.npmjs.com/package/hiredis)。 该`hiredis`包具有许多性能优势。 要开始我们的开发，首先需要安装`redis`。 在下一节中，我们将在项目中设置分布式缓存。](https://www.npmjs.com/package/hiredis)

# 使用 redis 设置我们的分布式缓存

为了理解缓存机制，让我们举一个实际的例子并实现分布式缓存。 我们将围绕购物车示例进行改进。 由于将业务功能划分为不同的服务是一件好事，因此我们将库存服务和结帐服务划分为两个不同的服务。 因此，无论何时用户向购物车添加任何内容，我们都不会持久化数据，而是将其暂时存储，因为这不是永久性的或功能更改的数据。 我们会将这种短暂的数据保存到 Redis 中，因为它的读取效率非常高。 我们针对这个问题的解决方案分为以下几个步骤:

1.  首先我们专注于建立我们的`redis`客户端。 就像所有通过`docker pull redis`拉出 docker 图像一样。
2.  一旦图像在我们的本地，只需点击`docker run --name tsms -d redis`。 也有持久性存储卷的选项。 您只需要添加一个参数`docker run --name tsms -d redis redis-server --appendonly yes`。

3.  验证 redis 通过命令运行只需点击`redis-cli`，你应该可以看到输出 pong。
4.  是时候在 Node.js 中使用字符串了。 通过添加`npm install redis --save`和`npm install @types/redis --save`来安装模块。
5.  通过`import * as redis from 'redis'; let client=redis.createClient('127.0.0.1', 6379);`创建客户端。
6.  使用 Redis 就像任何其他数据存储:

```
redis.get(req.userSessionToken + '_cart', (err, cart) => { if (err) 
 { 
    return next(err); 
 } 
//cart will be array, return the response from cache }
```

7.  同样地，你也可以在需要的时候使用 redis。 它甚至可以用作命令库。 有关详细文档，请查看此链接([https://www.npmjs.com/package/redis](https://www.npmjs.com/package/redis))。

We had to replicate the code in each of the three service for Redis. To avoid that in the later section we would be using Bit: a code sharing tool.

在下一节中，我们将了解如何对微服务进行版本控制，并使我们的微服务具有故障安全机制。

# 总结

在本章中，我们讨论了微服务之间的协作。 有三种微服务协作。 基于命令的协作(其中一个微服务使用 HTTP POST 或 PUT 让另一个微服务执行任何操作)、基于查询的协作(一个微服务利用 HTTP GET 来查询另一个服务的状态)、 以及基于事件的协作(一个微服务向另一个微服务公开一个事件提要，后者可以通过不断轮询提要来订阅任何新事件)。 我们看到了各种协作技术，其中包括发布-子模式和下一代通信技术，比如 gRPC、Thrift 等等。 我们看到了通过服务总线进行通信，以及如何在微服务之间共享代码。

在下一章中，我们将探讨测试、监控和文档方面的内容。 我们将研究我们可以进行的不同类型的测试，以及如何编写测试用例，并在将它们发布到生产环境之前执行它们。 接下来，我们将研究使用 PACT 进行契约测试。 然后，我们将继续进行调试，并研究如何利用调试和分析工具来有效地监控协作门户中的瓶颈。 最后，我们将使用任何人都可以阅读的 Swagger 为我们的微服务生成文档。**