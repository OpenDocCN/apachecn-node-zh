# 第四章。中央处理器剖析

概要分析很无聊，但它是一种很好的软件分析形式，您可以在其中测量资源使用情况。这种使用是随着时间的推移和有时在特定的工作负载下测量的。资源可以是应用程序正在使用的任何东西，无论是内存、磁盘、网络还是处理器。更具体地说，CPU 分析允许您分析您的函数如何以及有多少使用处理器。您还可以分析相反的情况，即处理器未被使用或空闲时间。

Node.js 并不主要用于持续的 CPU 密集型任务，有时，对于性能分析，重要的是要确定占用处理器的密集型任务的方法，并防止其他任务执行得更好。您可能会发现巨大的调用堆栈持续占用处理器，或者重复的递归任务没有像您预期的那样结束。有几种技术，例如拆分和调度任务，而不是在它们阻塞事件循环时持续运行它们。

你可能会问为什么这些任务如此可怕。答案很简单；Node.js 围绕一个事件循环运行，这意味着当您的代码结束一个特定的任务时，循环重新启动，挂起的事件被调度。如果您的代码没有结束，应用程序的其余部分将保持待机状态，直到任务完成。您需要能够将一个大任务分解成几个小任务，这样您的应用程序才能运行良好。

应用程序的主要目标应该是使用尽可能少的资源，因此使用尽可能少的处理器时间是理想的。这相当于大部分时间都在主线程中空闲运行。这是调用堆栈最小的时候。从基本的 Node.js 角度来看，这应该是零级。

分析处理器时，我们通常以一定的频率对调用堆栈进行采样，并分析堆栈在采样周期内如何变化(增加或减少)。如果您使用操作系统中的 profilers，堆栈中的项目可能比您预期的要多，因为您将获得 Node.js 和 V8 的内部调用。

本章将涵盖以下主题:

*   输入输出库
*   斐波纳契
*   火焰图
*   分析备选方案

# 输入输出库

Node.js 使用的能够跨多个平台环境执行异步 I/O 操作的库是 **libuv** 。这是一个开源库。实际上，它被平台用来提供类似于其他语言(如 Luvit 和 Lua)的功能。 **Libuv** 是一个跨平台的库，它使用每个平台可能的最佳方法来实现最佳的 I/O 性能，并且仍然公开了一个通用的 API。

这个库负责网络任务(TCP 和 UDP 套接字)、DNS 请求、文件系统操作等等。它是访问文件、列出目录内容、监听套接字连接和执行子进程的库。下图显示了 Node.js 如何在同一级别使用 V8 和 libuv:

![The I/O library](graphics/4183_04_01.jpg)

可以看到 libuv 并不依赖于 V8 与 I/O 交互，它是一个有自己线程池的 C 库。这个线程池的设计是为了快速，避免过于频繁地创建和销毁任务线程，因为它们非常昂贵。该库处理从网络到文件系统的许多输入/输出任务。它负责 Node.js 公开`fs`、`net`、`dns`以及更多的 API。在事件循环期间，您的代码可以请求输入/输出数据。这是经过处理的，当准备就绪时(也就是说，您的请求的全部或部分已经为您准备就绪)，它会触发一个事件，希望在下一个事件循环中处理该事件。下图描述了线程池的工作方式。您的代码在事件循环(绿色)中运行，libuv 在单独的线程(蓝色)中运行，并在每个周期之前触发代码的事件(橙色):

![The I/O library](graphics/4183_04_02.jpg)

这意味着，如果您请求一个文件的内容并开始执行大量密集的操作，它不会影响文件操作，因为它是在您的范围之外完成的。因此，虽然 Node.js 是单线程的，但是有几个操作是在单独的线程中完成的(从一个池中)。这一点很重要，因为我们要对代码进行概要分析，以便区分什么是 Node.js 瓶颈、libuv (I/O)瓶颈和仅仅是系统瓶颈。

## 斐波那契

让我们来看一个例子。半信半疑。这实际上是一个非常常见且备受批评的例子，涉及斐波那契数列。让我们创建一个简单的名为`fib.js`的 HTTP 服务器文件，它将基于特定长度的斐波那契序列的数的总和，用响应来回答每个请求。这里没有依赖关系，只有普通的 Node.js。此外，我们将使用`ab`命令(Apache Benchmark)向我们的服务器发出一些请求。如果你有一台基于 Debian 的机器，你只需要安装`apache2-utils`就可以使用这个命令:

```
var http   = require("http");
var server = http.createServer();

server.on("request", function (req, res) {
  var f = fibonacci(40);

  return res.end("" + f);
});

server.listen(3000);

function fibonacci(n) {
  return (n < 2 ? n : fibonacci(n - 1) + fibonacci(n - 2));
}
```

可以看到，`fibonacci`函数是递归的(应该如此)，每次有新的请求到来就会被调用。看到这不会有那么好的表现，不应该感到惊讶。让我们开始，告诉 V8 我们想要一个配置文件日志:

```
$ node --prof fib.js

```

现在让我们用 10 个请求和两个并发连接来测试它。为了更清楚地理解，以下输出已被截断:

```
$ ab –n 10 –c 2 http://localhost:3000/
This is ApacheBench, Version 2.3 <$Revision: 1604373 $>
(...)
Concurrency Level:      2
Time taken for tests:   18.851 seconds
Complete requests:      10
Failed requests:        0
(...)
Requests per second:    0.52 [#/sec] (mean)
Time per request:       3822.383 [ms] (mean)
(...)

```

您可以看到每个请求花费了 2 秒钟(每秒半个请求)。看起来不太好，是吗？让我们停止服务器。您应该会在同一个文件夹中看到一个`isolate*.log`文件。你可以用 V8 嘀嗒处理器打开。有在线版的([http://V8 . googlecode . com/SVN/trunk/tools/tick-processor . html](http://v8.googlecode.com/svn/trunk/tools/tick-processor.html)，如果你愿意；或者如果你和我一样有节点源，你会在`deps/v8/tools/tick-processor.html`找到。

![Fibonacci](graphics/4183_04_03.jpg)

点击**选择文件**并选择你的日志。该工具将类似于下面的咀嚼类过程、投掷类返回输出。再一次，一些输出被移除:

```
Statistical profiling result from null, (...).

(...)

 [JavaScript]:
   ticks  total  nonlib   name 
  14267   89.1%  100.0%  LazyCompile: *fibonacci fib.js:15:19
      1    0.0%    0.0%  Stub: reinitialize

(...)

 [Bottom up (heavy) profile]:
(...)
   ticks parent  name
  14267   89.1%  LazyCompile: *fibonacci fib.js:15:19
  14267  100.0%    LazyCompile: *fibonacci fib.js:15:19
  14267  100.0%      LazyCompile: *fibonacci fib.js:15:19
  14267  100.0%        LazyCompile: *fibonacci fib.js:15:19
  14267  100.0%          LazyCompile: *fibonacci fib.js:15:19
```

我们的`fibonacci`功能是一直在使用我们的处理器。您可以在`Bottom up (heavy) profile`部分注意到递归模式。由于函数的递归性，您可以看到不同的级别(缩进)。

### 类型

请注意，在运行您自己的测试时，您应该将服务器的运行时间限制在基准测试的时间内(如本例所示)。如果您让服务器运行的时间超过这个时间，那么您的功能的使用将与空闲时间混在一起。

在我们的例子中，拆分代码并不容易，甚至更好，因为操作真的很简单(加两个数字)。在其他用例中，您可以通过修改您的代码来优化一些操作，例如，使用[第 2 章](2.html "Chapter 2. Development Patterns")、*开发模式*中显示的一些技术。

在这种情况下，另一种提高性能的方法是使用名为**记忆**的技术。这就是包装一个函数，并基于参数缓存它的返回值。这意味着，对于一组特定的参数，一个函数将只被调用一次，然后返回值将被缓存并重复使用。当然，这并不适用于所有情况。让我们在我们的服务器上尝试一下:

```
var http   = require("http");
var server = http.createServer();

fibonacci = memoize(fibonacci);

server.on("request", function (req, res) {
  var f = fibonacci(40);

  return res.end("" + f);
});

server.listen(3000);

function fibonacci(n) {
  return (n < 2 ? n : fibonacci(n - 1) + fibonacci(n - 2));
}

function memoize(f) {
  var cache = {};

  return function memoized(n) {
    return cache[n] || (cache[n] = f[n]);
  };
}
```

有一些模块可以帮助您实现这一结果。在我们的例子中，我们添加了一个`memoizing`函数，并且实际上用它自己覆盖了这个函数— `memoized`。这很重要，因为函数递归调用自己，所以它真的需要被覆盖。

这将缓存对它的每个调用，因此只有第一个`fibonacci(40)`调用不会使用缓存。而且，由于函数用 *n-1* 和 *n-2* 调用自己，一半的调用会被缓存，所以第一次调用会更快。运行`ab`测试会得到非常不同的结果:

```
$ ab -n 10 -c 2 http://localhost:3000/
This is ApacheBench, Version 2.3 <$Revision: 1604373 $>
(...)
Concurrency Level:      2
Time taken for tests:   0.038 seconds
Complete requests:      10
Failed requests:        0
(...)
Requests per second:    263.86 [#/sec] (mean)
Time per request:       7.580 [ms] (mean)
(...)

```

这在每秒超过 250 个请求时要好得多。这显然是一个糟糕的基准测试，因为如果您将请求的数量增加到几千个，这个数字会更好(几千个)。如果您使用 V8 Tick 处理器，您会注意到函数调用不再存在:

```
(...)
[JavaScript]:
ticks  total  nonlib   name
 1    0.1%   12.5%  Stub: ToBooleanStub(Null,SpecObject)
 1    0.1%   12.5%  LoadMegamorphic: args_count: 0
 1    0.1%   12.5%  LazyCompile: ~httpSocketSetup _http_common...
 1    0.1%   12.5%  LazyCompile: ~exec native regexp.js:98:20
 1    0.1%   12.5%  LazyCompile: ~UseSparseVariant native array...
 1    0.1%   12.5%  LazyCompile: ADD native runtime.js:99:13
(...)

```

这显然是一个糟糕而又非常简单的例子。每个应用程序都是不同的，分析它需要了解更多。使用开发平台有助于集中你对该主题的知识，并帮助你更容易地提高加班。

![Fibonacci](graphics/4183_04_04.jpg)

## 火焰图

火焰图是一种可视化技术，用于分析应用程序，并快速、准确地发现最常用的功能。这些图表取代或补充了以前的日志文本输出，因为它们提供了一种更令人愉快和简单的分析方式。

火焰图是由几个堆叠的块组成的，每个块代表一个函数调用。它通常水平显示使用时间(不一定按顺序)。当一个函数被另一个函数调用时，第一个函数显示在前一个函数的上面。使用这个规则，你可以计算出顶部的块肯定会比底部的块小(水平方向)。这创建了一个视觉上类似火焰的图形。此外，这些块通常使用暖色(如红色和橙色)，因此图形看起来确实像火焰。

这些可以与不同的目标一起使用，例如查看内存使用和泄漏。例如，您可以创建一个火焰图来查看中央处理器是如何使用的(繁忙的中央处理器是一个努力工作、不间断的中央处理器。空闲的中央处理器是无所事事的)。另一个很好的用途是查看应用程序何时空闲，与 CPU 和内存相比，输入/输出是否非常慢，当应用程序阻止(停止)等待来自磁盘或网络的文件时，这是正常的。这叫做脱离 CPU。这在冷色(蓝色和绿色)中更容易看到。两个 CPU 火焰图的混合还可以让您很好地理解应用程序的行为。

创建火焰图在 Node.js 上还不容易，这取决于你的系统。由于 V8 有`perf_events`支持([https://codereview.chromium.org/70013002](https://codereview.chromium.org/70013002))，我目前发现在 Linux 盒子上使用`perf`命令和`perf_events`要容易得多，但是你有其他选择，比如 DTrace([http://www.brendangregg.com/flamegraphs.html](http://www.brendangregg.com/flamegraphs.html))。我们现在就试试吧。给自己买一台 Ubuntu 机器(或者虚拟机)，安装一些依赖项。请注意，其中一些取决于您当前的内核版本:

```
$ sudo apt-get update
$ sudo apt-get install linux-tools-common linux-tools-`uname –r`

```

现在让我们运行我们的节点服务器，告诉 V8 我们想要`perf_events`输出。这次我们在后台运行，这样更容易看到它的 PID，之后运行`perf`:

```
$ node –-perf-basic-prof fib.js &
[1] 30462

```

这就是我们需要的 PID——`30462`。那我们运行`perf`收集事件一分钟左右。命令在完成之前不会返回(监听事件一分钟)，因此您需要打开另一个控制台来运行基准命令:

```
$ perf record -F 99 -p 30462 -g -- sleep 60
# on another console..
$ ab –n 1000 http://localhost:3000/

```

我们告诉 perf 在`30462`过程中以`99`赫兹的频率记录事件，启用呼叫图表(`-g`，并在`60`秒内这样做。过了这段时间，这个命令应该结束了。第一个版本的代码非常慢，需要 60 秒以上才能完成，所以用户可以在一分钟后停止它。第二个版本要快得多，没必要这么做。

你可以看看目录，注意到有一个`perf.data`文件。现在我们需要告诉`perf`读取这个文件并显示跟踪输出。我们将使用它并将其转换成火焰图。为此，我们将使用 Brendan Gregg 创建的堆栈跟踪可视化工具。这个输出将被转换成一个 SVG 文件。然后，您可以在您最喜欢的浏览器中打开它。首先让我们得到这个堆栈输出:

```
$ perf script > stack01.trace

```

现在，让我们下载堆栈跟踪可视化工具，并使用它来转换这个文件。你需要`git`来获得这个命令:

```
$ git clone --depth 1 http://github.com/brendangregg/FlameGraph
$ ./FlameGraph/stackcollapse-perf.pl < stack01.trace | ./FlameGraph/flamegraph.pl > stack01.svg

```

你现在应该有一个`stack01.svg`文件，可以与之交互。您可以单击水平块放大该级别，或者单击最低的块重置缩放。对于服务器的第一个版本，您应该会得到类似于下图的结果:

![Flame graphs](graphics/4183_04_05.jpg)

你可以清楚地看到将火焰推得更高的递归模式。有最初的大火焰，旁边还有其他火焰。如果你点击第二个火焰的底部，你会看到类似如下的东西:

![Flame graphs](graphics/4183_04_06.jpg)

现在你可以清楚地看到你的处理器被这个低效的递归函数耗尽了。检查火焰图时，看一下底线。它将显示我们在日志处理器的初始输出中看到的信息，例如使用百分比。

如果我们使用第二个服务器版本，如果我们想看到任何有用的东西，我们需要增加基准负载。尝试使用以下步骤为第二个服务器版本创建火焰图:

```
$ node –-perf-basic-prof fib.js &
[1] 30611
$ perf record -F 99 -p 30611 -g -- sleep 60
# on another console..
$ ab –n 10000 http://localhost:3000/
$ perf script > stack02.trace
$ ./FlameGraph/stackcollapse-perf.pl < stack02.trace | ./FlameGraph/flamegraph.pl > stack02.svg

```

现在在浏览器中打开这个新的 SVG，看看火焰是如何变细的。这意味着尽管堆栈大小可能很大，但该堆栈大小的持续时间很短。类似这样的事情比较正常:

![Flame graphs](graphics/4183_04_07.jpg)

在图的底部，你总是会看到`node`或`main`作为 Node.js 大部分时间都在主线程上。在节点或 main 的顶部，您会看到其他行。每一个堆叠的线意味着下面的线的呼叫。当你到达火焰的顶端时，你将开始看到实际的 JavaScript 代码。您会发现对 Node.js 内部函数的许多调用都与事件和`libuv`任务有关。

### 类型

根据经验，火焰图形具有巨大而宽的火焰意味着过度的 CPU 使用。火焰高但较细的火焰图意味着较低的 CPU 使用率。

## 分析备选方案

根据操作系统，还有其他方法可以分析应用程序的处理器使用情况。如果你使用支持的系统，你可以尝试 DTrace。我不建议在 Linux 盒子上使用它。此外，如果您没有使用基于 Illumos 的系统，您可能会忘记它，至少对于 Node.js. Linux 有更多的调用堆栈调试工具，您可以使用它们来记录堆栈，然后生成火焰图。

Node.js 有剖析模块，甚至调用堆栈跟踪模块，但是我建议你避免在语言级别调试它们，转到操作系统级别。它速度更快，对代码的干扰更小，通常能让你对你试图描述的行为或不良行为有更全面的了解。请记住，系统不仅仅是您的应用程序，在您的堆栈范围之外还有其他因素会影响您的性能。

您可以将火焰图用于其他类型的数据。例如，您可以跟踪设备输入/输出`calls`或`syscalls`。您可以过滤对特定函数调用的跟踪，以查看函数何时使用以及使用多长时间。您可以跟踪内存分配，而不是收集分配调用，您可以收集以字节为单位的分配大小。这种类型的图有许多用途，因为它对于可视化分析应用程序行为非常方便。

# 总结

在当今的环境中，能够分析应用程序以识别瓶颈非常重要，尤其是在处理器和内存级别。系统很复杂，分为几层，所以如果没有一些工具和可视化技术，例如火焰图，使用调用堆栈分析处理器的使用可能会非常困难。总的来说，在进行概要分析之前，您应该关注您的代码质量。

正如您在我们的示例中看到的，服务器的一个简单有效的解决方案是缓存结果。缓存是一项非常重要的技术，通常对平衡资源使用至关重要。通常情况下，你有可用的内存，最好在一小段时间内缓存一个结果，而不是每次都处理它，尤其是当结果不可测量的时候。

接下来，我们将了解您应该如何使用和存储数据，以及应该如何、何时缓存数据以及缓存多长时间。我们将了解一些缓存方法的优缺点，以便您可以更好地选择自己的道路，使您的应用程序成为性能最好的应用程序。